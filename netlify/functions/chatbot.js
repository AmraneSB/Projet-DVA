import fetch from "node-fetch";

export async function handler(event) {
  try {
    if (event.httpMethod === "GET") {
      return {
        statusCode: 200,
        body: JSON.stringify({ ok: true, message: "Chatbot function alive üöÄ" })
      };
    }

    // R√©cup√©ration du message et des colonnes depuis le frontend
    let payload = {};
    if (event.body) {
      payload = JSON.parse(event.body);
    }

    const { message, columns } = payload;
    const key = process.env.OPENAI_API_KEY;

    // Si la cl√© OpenAI n'est pas d√©finie, on renvoie un graphique par d√©faut
    if (!key) {
      return {
        statusCode: 200,
        body: JSON.stringify({
          column: columns[0] || "population",
          type: "bar",
          explanation: "Cl√© OpenAI manquante, g√©n√©ration d'un graphique par d√©faut"
        })
      };
    }

    // Prompt pour OpenAI : force une r√©ponse JSON stricte
    const prompt = `
Tu es un assistant pour cr√©er des graphiques √† partir de donn√©es.
Colonnes disponibles : ${columns.join(", ")}
Utilisateur demande : "${message}"

R√©ponds STRICTEMENT en JSON :
{
  "column": "...",
  "type": "bar | pie | line",
  "explanation": "..."
}
`;

    // Appel √† l'API OpenAI
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${key}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "gpt-4.1-mini",
        messages: [{ role: "user", content: prompt }]
      })
    });

    const data = await response.json();

    // R√©cup√®re le contenu JSON renvoy√© par l'IA
    const content = data.choices[0].message.content;

    // Retour vers le frontend
    return {
      statusCode: 200,
      body: content
    };

  } catch (err) {
    return {
      statusCode: 500,
      body: JSON.stringify({ ok: false, error: err.message })
    };
  }
}
